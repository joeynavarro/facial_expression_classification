{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import dirname, join\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "\n",
    "#custom imports\n",
    "from model_notebook.model_backend.transformers import  transforms\n",
    "from model_notebook.built_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading Data Transformers for Augmentation...\n"
     ]
    }
   ],
   "source": [
    "#basically batch size\n",
    "cut_size = 43\n",
    "\n",
    "print('===> Loading Data Transformers for Augmentation...')\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.TenCrop(cut_size),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading Color To Grayscale Function...\n"
     ]
    }
   ],
   "source": [
    "print('===> Loading Color To Grayscale Function...')\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Reading Image 0...\n",
      "===> Converting Image to Grayscale...\n",
      "===> Creating Image Augmentation Transformations...\n",
      "===> Loading Model...\n",
      "===> Recognizing Face...\n",
      "===> Predicting and Plotting...\n",
      "===> Saving Prediction Figure...\n",
      "===> Finished Predicting Image 0!!!\n",
      " \n",
      "===> Reading Image 1...\n",
      "===> Converting Image to Grayscale...\n",
      "===> Creating Image Augmentation Transformations...\n",
      "===> Loading Model...\n",
      "===> Recognizing Face...\n",
      "===> Predicting and Plotting...\n",
      "===> Saving Prediction Figure...\n",
      "===> Finished Predicting Image 1!!!\n",
      " \n",
      "===> Reading Image 2...\n",
      "===> Converting Image to Grayscale...\n",
      "===> Creating Image Augmentation Transformations...\n",
      "===> Loading Model...\n",
      "===> Recognizing Face...\n",
      "===> Predicting and Plotting...\n",
      "===> Saving Prediction Figure...\n",
      "===> Finished Predicting Image 2!!!\n",
      " \n",
      "===> Reading Image 3...\n",
      "===> Converting Image to Grayscale...\n",
      "===> Creating Image Augmentation Transformations...\n",
      "===> Loading Model...\n",
      "===> Recognizing Face...\n",
      "===> Predicting and Plotting...\n",
      "===> Saving Prediction Figure...\n",
      "===> Finished Predicting Image 3!!!\n",
      " \n",
      "===> Reading Image 4...\n",
      "===> Converting Image to Grayscale...\n",
      "===> Creating Image Augmentation Transformations...\n",
      "===> Loading Model...\n",
      "===> Recognizing Face...\n",
      "===> Predicting and Plotting...\n",
      "===> Saving Prediction Figure...\n",
      "===> Finished Predicting Image 4!!!\n",
      " \n",
      "===> Reading Image 5...\n",
      "===> Converting Image to Grayscale...\n",
      "===> Creating Image Augmentation Transformations...\n",
      "===> Loading Model...\n",
      "===> Recognizing Face...\n",
      "===> Predicting and Plotting...\n",
      "===> Saving Prediction Figure...\n",
      "===> Finished Predicting Image 5!!!\n",
      " \n"
     ]
    }
   ],
   "source": [
    "directory = './predictor_images_to_predict/'\n",
    "counter = 0\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "        \n",
    "        print('===> Reading Image ' + str(counter) + '...')\n",
    "        raw_img = io.imread(os.path.join(directory, filename))\n",
    "\n",
    "        print('===> Converting Image to Grayscale...')\n",
    "        gray = rgb2gray(raw_img)\n",
    "        gray = resize(gray, (48,48), mode='symmetric').astype(np.uint8)\n",
    "\n",
    "        img = gray[:, :, np.newaxis]\n",
    "\n",
    "        img = np.concatenate((img, img, img), axis=2)\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        print('===> Creating Image Augmentation Transformations...')\n",
    "        inputs = transform_test(img)\n",
    "\n",
    "        class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "        print('===> Loading Model...')\n",
    "        net = VGG('VGG19')\n",
    "        checkpoint = torch.load(os.path.join('./model_checkpoints/CK+_VGG19/', 'emoclass_model.t7'))\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "        net.cuda()\n",
    "        net.eval()\n",
    "\n",
    "        ncrops, c, h, w = np.shape(inputs)\n",
    "\n",
    "        inputs = inputs.view(-1, c, h, w)\n",
    "        inputs = inputs.cuda()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        outputs_avg = outputs.view(ncrops, -1).mean(0)  # avg over crops\n",
    "\n",
    "        score = F.softmax(outputs_avg, -1)\n",
    "        _, predicted = torch.max(outputs_avg.data, 0)\n",
    "\n",
    "        print('===> Recognizing Face...')\n",
    "        # Facial Recognition\n",
    "        dir_path = './model_checkpoints/predictor_weights'\n",
    "        \n",
    "        protoPath = join(dir_path, \"deploy.prototxt\")\n",
    "        modelPath = join(dir_path, 'weights.caffemodel')\n",
    "\n",
    "        model = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "\n",
    "\n",
    "        \n",
    "        #read the image using cv2\n",
    "        face_image = cv2.imread(os.path.join(directory, filename))\n",
    "        face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #accessing the image.shape tuple and taking the elements\n",
    "        (h,w) = face_image.shape[:2]\n",
    "        \n",
    "        #get our blog which is our input image\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(face_image, (300, 300)), 1.0, (300, 300), (104.0 , 177.0, 123.0))\n",
    "        \n",
    "        #input the blob into the model and get back the detections\n",
    "        model.setInput(blob)\n",
    "        detections = model.forward()\n",
    "        \n",
    "        #Iterate over all of the faces detected and extract their start and end points\n",
    "        count = 0\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype('int')\n",
    "            \n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            \n",
    "            #if the algorithm is more than 16.5% confident that the detection is a face, show a rectangle around it\n",
    "            if (confidence > 0.5):\n",
    "                cv2.rectangle(face_image, (startX, startY), (endX, endY), (0, 255, 0), 4)\n",
    "                count = count + 1\n",
    "             \n",
    "        print('===> Predicting and Plotting...')\n",
    "        # instantiate plot\n",
    "        fig, ax = plt.subplots(2, 2, figsize = (17, 13))\n",
    "        \n",
    "        \n",
    "        #fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace= 0.3, hspace=0.3)\n",
    "        \n",
    "        \n",
    "        # plot quadrant I\n",
    "        ax[0, 1].set_title('Image Face Detection', fontsize = 25, pad = 20, style = 'oblique',  fontname = 'Verdana')\n",
    "        ax[0, 1].imshow(face_image)\n",
    "        ax[0, 1].set_xticks([])\n",
    "        ax[0, 1].set_yticks([])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # plot quadrant II\n",
    "        ax[0, 0].imshow(raw_img)\n",
    "        ax[0, 0].set_title('Original Image', fontsize = 25, pad = 20, style = 'oblique',  fontname = 'Verdana')\n",
    "        ax[0, 0].set_xticks([])\n",
    "        ax[0, 0].set_yticks([])\n",
    "    \n",
    "\n",
    "\n",
    "        # plot quadrant III\n",
    "        ind = 0.1 + 0.6 * np.arange(len(class_names))    # the x locations for the groups\n",
    "        width = 0.4       # the width of the bars: can also be len(x) sequence\n",
    "        \n",
    "        color_list = ['red','olive','darkslategray','yellow','teal','springgreen','lightgray']\n",
    "        \n",
    "        for i in range(len(class_names)):\n",
    "             ax[1, 0].bar(ind[i], (score * 100).data.cpu().numpy()[i], width, color=color_list[i])\n",
    "\n",
    "        ax[1, 0].set_title(\"Expression Prediction Scores \",fontsize = 25, pad = 20, style = 'oblique',  fontname = 'Verdana')\n",
    "        ax[1, 0].set_xlabel(\"Expression Type\",fontsize = 16, labelpad = 10, style = 'oblique',  fontname = 'Verdana')\n",
    "        ax[1, 0].set_ylabel(\"Prediction Confidence in %\",fontsize = 16, labelpad = 10,  fontname = 'Verdana', style = 'oblique')\n",
    "        ax[1, 0].set_xticks(ind)\n",
    "        ax[1, 0].set_xticklabels( class_names, fontsize = 13,  fontname = 'Verdana') \n",
    "        \n",
    "        # plot quadrant IV\n",
    "        # emoji read in and transformations\n",
    "        im = Image.open('./data/model_emojis/%s.png' % str(class_names[int(predicted.cpu().numpy())]))\n",
    "        \n",
    "        # expand emoji so it's not pixalated\n",
    "        \n",
    "        desired_size = 500\n",
    "        old_size = im.size  # old_size[0] is in (width, height) format\n",
    "\n",
    "        ratio = float(desired_size) / max(old_size)\n",
    "        new_size = tuple([int(x*ratio) for x in old_size])\n",
    "        \n",
    "        # use thumbnail() or resize() method to resize the input image\n",
    "        im = im.resize(new_size, Image.ANTIALIAS)\n",
    "        \n",
    "        # create a new image and paste the resized on it\n",
    "        new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
    "        new_im.paste(im, ((desired_size-new_size[0]) // 2,\n",
    "                    (desired_size-new_size[1]) // 2))\n",
    "        delta_w = desired_size - new_size[0]\n",
    "        delta_h = desired_size - new_size[1]\n",
    "        padding = (delta_w // 2, delta_h // 2, delta_w-(delta_w // 2), delta_h-(delta_h // 2))\n",
    "        new_emoji = ImageOps.expand(im, padding)\n",
    "        \n",
    "        ax[1, 1].imshow(new_emoji)\n",
    "        ax[1, 1].set_title('Emoji Expression', fontsize=25, pad = 20, style = 'oblique',  fontname = 'Verdana')\n",
    "        ax[1, 1].set_xlabel(\" %s Face is Being Expressed\" %str(class_names[int(predicted.cpu().numpy())]),fontsize = 30, labelpad = 20,  fontname = 'Verdana', fontweight = 'bold')\n",
    "        ax[1, 1].set_xticks([])\n",
    "        ax[1, 1].set_yticks([])\n",
    "        \n",
    "        fig.tight_layout(h_pad= 5.5, pad=5)\n",
    "\n",
    "#         plt.show()\n",
    "        print('===> Saving Prediction Figure...')\n",
    "        plt.savefig(os.path.join('./predictor_predicted_expression/', filename))\n",
    "        plt.close()\n",
    "        print('===> Finished Predicting Image ' + str(counter) + '!!!')\n",
    "        print(' ')\n",
    "        counter += 1\n",
    "\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
